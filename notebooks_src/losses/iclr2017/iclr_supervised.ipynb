{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.objectives import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from notebooks_src.configs import configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evan_sparse_softmax_cross_entropy(y_pred, y_true,depth):\n",
    "    #y_pred =tf.Print(input_=y_pred,data=[])\n",
    "    log_sm = log_softmax(y_pred)\n",
    "    y_true = convert_to_one_hot_encoding(y_true, depth)\n",
    "    xent = -tf.reduce_sum(y_true * log_sm, axis=-1)\n",
    "    return xent\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot_encoding(tens,depth):\n",
    "    tens=tf.squeeze(tens)\n",
    "    max_index = tf.reduce_max(tens)\n",
    "\n",
    "    one_hot= tf.one_hot(indices=tens,depth=depth,axis=-1)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_softmax(y_pred):\n",
    "    #y_pred = tf.cast(y_pred, tf.float64)\n",
    "    max_y_pred = tf.reduce_max(y_pred,axis=-1, keep_dims=True)\n",
    "    max_subtracted = y_pred - max_y_pred\n",
    "    log_sm = max_subtracted - tf.log(tf.reduce_sum(tf.exp(max_subtracted),axis=-1,keep_dims=True))\n",
    "    #log_sm= tf.cast(log_sm, tf.float32)\n",
    "    return log_sm\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def class_loss(y_pred, y_true, obj_tens):    \n",
    "\n",
    "    y_pred = add_epsilon(y_pred)\n",
    "    \n",
    "    losses = evan_sparse_softmax_cross_entropy(y_pred,y_true,depth = configs[\"num_classes\"])\n",
    "    #losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_pred,labels=y_true)\n",
    "    losses = mask_tens(losses, mask=tf.squeeze(obj_tens))\n",
    "    mean_loss = average_nonzero_elements(losses)\n",
    "\n",
    "    return mean_loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obj_loss(y_pred, y_true):\n",
    "    y_pred = add_epsilon(y_pred)\n",
    "    \n",
    "    losses = evan_sparse_softmax_cross_entropy(y_pred,y_true, depth=tf.constant(2))\n",
    "    loss = tf.reduce_mean(losses)\n",
    "    num_nonzero = tf.count_nonzero(y_true)\n",
    "    zeros = lambda: tf.constant(0.0)\n",
    "    da_loss = lambda: loss\n",
    "    # if all elements of y_true are zero (aka no objects) then return loss of zero because likely unlabelled frame\n",
    "    real_loss = tf.case([(tf.greater(num_nonzero,tf.constant(0,dtype=tf.int64)),da_loss)], default=zeros)\n",
    "    #todo stop gradient if 0\n",
    "    return real_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coord_loss(y_pred, y_true, obj_tens):\n",
    "#     y_pred = tf.Print(input_=y_pred, data=[tf.reduce_min(y_pred), tf.reduce_max(y_pred)], message=\"min y_pred, max y_pred: \")\n",
    "#     y_true = tf.Print(input_=y_true, data=[tf.reduce_min(y_true), tf.reduce_max(y_true)], message=\"min y_true, max y_true: \")\n",
    "    losses = smooth_l1(tf.subtract(y_true, y_pred))\n",
    "    nans = tf.reduce_any(tf.is_nan(losses))\n",
    "    #losses = tf.Print(input_=losses, data=[nans], message=\"after smooth l1 nan? \")\n",
    "    \n",
    "    mask = tf.concat(values=[obj_tens, obj_tens], concat_dim=3,)\n",
    "    losses = mask_tens(losses,mask)\n",
    "\n",
    "    losses = zero_out_nans(losses)\n",
    "    return tf.reduce_mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruction_loss(y_pred, y_true):\n",
    "    return tf.reduce_mean(mean_squared_error(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def smooth_l1(x):\n",
    "    #x = tf.Print(input_=x, data=[tf.reduce_min(x), tf.reduce_max(x)], message=\"min x, max x: \")\n",
    "    abs_x = tf.abs(x)\n",
    "    \n",
    "    lt_one = tf.less(abs_x, tf.ones_like(abs_x))\n",
    "    \n",
    "    \n",
    "    do_if_lt_one = tf.scalar_mul(x=tf.pow(x,2),scalar=0.5)\n",
    "\n",
    "    do_if_gt_one = tf.subtract(abs_x,0.5)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = tf.where(lt_one, \n",
    "                            do_if_lt_one,\n",
    "                            do_if_gt_one)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_lbl_channels(y_true):\n",
    "    y_true_xy,y_true_wh,y_true_obj_y_true_cls = tf.split(value=y_true,num_split=3,split_dim=3)\n",
    "    y_true_obj, y_true_cls = tf.split(value=y_true_obj_y_true_cls, num_split=2, split_dim=3)\n",
    "    \n",
    "    y_mask_obj = tf.cast(y_true_obj, tf.float32)\n",
    "    y_true_obj = tf.squeeze(tf.cast(y_true_obj, tf.int32))\n",
    "    y_true_cls = tf.squeeze(tf.cast(y_true_cls, tf.int32))\n",
    "    return y_true_xy,y_true_wh,y_true_obj, y_true_cls, y_mask_obj\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_pred_channels(y_pred):\n",
    "    y_pred_xy,y_pred_wh,y_pred_obj, y_pred_cls1,y_pred_cl2 = tf.split(value=y_pred,num_split=5,split_dim=3)\n",
    "    y_pred_cls = tf.concat(values=[y_pred_cls1,y_pred_cl2], concat_dim=3)\n",
    "    \n",
    "    \n",
    "    return  y_pred_xy,y_pred_wh,y_pred_obj, y_pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    alpha, beta = [configs[k] for k in [\"alpha\", \"beta\"]]\n",
    "    \n",
    "    y_pred_xy,y_pred_wh,y_pred_obj, y_pred_cls = extract_pred_channels(y_pred)\n",
    "    \n",
    "    y_true_xy,y_true_wh,y_true_obj, y_true_cls,y_mask_obj = extract_lbl_channels(y_true)\n",
    "    \n",
    "    cls_loss = class_loss(y_pred_cls, y_true_cls,y_mask_obj)\n",
    "    o_loss = obj_loss(y_pred_obj,y_true_obj)\n",
    "    \n",
    "    xy_loss = coord_loss(y_pred_xy, y_true_xy, y_mask_obj)\n",
    "    \n",
    "    \n",
    "    wh_loss = coord_loss(y_pred_wh, y_true_wh, y_mask_obj)\n",
    "    \n",
    "    \n",
    "    \n",
    "    xy_loss = tf.scalar_mul(alpha, xy_loss)\n",
    "    #cls_loss = tf.Print(input_=cls_loss,data=[cls_loss, o_loss, xy_loss, wh_loss], message=\"cls_loss, obj_loss, xy_loss, wh_loss:  \")\n",
    "    wh_loss = tf.scalar_mul(beta, wh_loss)\n",
    "    loss = tf.add_n([xy_loss, wh_loss, o_loss, cls_loss])\n",
    "    #loss = tf.Print(input_=loss, data=[loss], message=\"final loss: \")\n",
    "    \n",
    "    #todo: stop gradient if this is 0\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8607\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sess = tf.InteractiveSession()\n",
    "    brn=tf.contrib.distributions.Bernoulli(p=0.5)\n",
    "    uni = tf.contrib.distributions.Uniform(0.,1.)\n",
    "    cat = tf.contrib.distributions.Categorical(p=4*[0.25])\n",
    "    nrm = tf.contrib.distributions.Normal(mu=0.,sigma=1.)\n",
    "    \n",
    "    \n",
    "    y_true_obj = tf.cast(brn.sample(sample_shape=(5,24,24,1)),tf.float32)\n",
    "    \n",
    "\n",
    "    y_pred_cls = uni.sample(sample_shape=(5,24,24, 4))\n",
    "    y_pred_obj = uni.sample(sample_shape=(5,24,24, 2))\n",
    "    y_pred_xy = nrm.sample(sample_shape=(5,24,24,2))\n",
    "    y_pred_wh = nrm.sample(sample_shape=(5,24,24,2))\n",
    "    y_true_xy = nrm.sample(sample_shape=(5,24,24,2))\n",
    "    y_true_wh = nrm.sample(sample_shape=(5,24,24,2))\n",
    "    y_true_cls = tf.cast(cat.sample(sample_shape=(5,24,24,1)), tf.float32)\n",
    "    \n",
    "    y_true_im = nrm.sample(sample_shape=(768,768,16))\n",
    "    y_pred_im = nrm.sample(sample_shape=(768,768,16))\n",
    "    \n",
    "    \n",
    "    outputs = tf.concat(values=[y_pred_xy,y_pred_wh,y_pred_obj, y_pred_cls], concat_dim=3)\n",
    "    gr_truth = tf.concat(values=[y_true_xy,y_true_wh,y_true_obj, y_true_cls], concat_dim=3)\n",
    "    loss= sess.run(compute_loss(gr_truth, outputs))\n",
    "    print loss\n",
    "    #print sess.run(yolo_semisupervised_loss(outputs, gr_truth))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'climate_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-f12a0cde42dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtf_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_lbl_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_lbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclimate_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0my_true_xy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true_wh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mask_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtf_lbl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'climate_gen' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #sess = tf.InteractiveSession()\n",
    "    pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
