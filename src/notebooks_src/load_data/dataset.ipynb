{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import MFDataset\n",
    "from os import listdir, system\n",
    "from os.path import isfile, join, isdir\n",
    "import numpy as np\n",
    "import imp\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import inspect\n",
    "import copy\n",
    "from util import get_camfiles,convert_nc_data_to_tensor\n",
    "# from labels.yolo_maker import make_yolo_masks_for_dataset, make_multiple_yolo_masks\n",
    "import random\n",
    "from configs import configs\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "\n",
    "    def __init__(self,images,labels):\n",
    "\n",
    "\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._num_examples = self._images.total_examples\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "    \n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "    \n",
    "    def shuffle(self):\n",
    "        pass\n",
    "\n",
    "    def next_batch(self, batch_size, shuffle=True):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        # Shuffle for the first epoch\n",
    "        if self._epochs_completed == 0 and start == 0 and shuffle:\n",
    "            \n",
    "            #shuffle files\n",
    "            seed = np.random.randint(0,1000)\n",
    "            self._images.shuffle(seed)\n",
    "            self._labels.shuffle(seed)\n",
    "\n",
    "        # Go to the next epoch\n",
    "        if start + batch_size > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            \n",
    "            # Get the rest examples in this epoch\n",
    "            rest_num_examples = self._num_examples - start\n",
    "            images_rest_part = self._images[start:self._num_examples]\n",
    "            labels_rest_part = self._labels[start:self._num_examples]\n",
    "            # Shuffle the data\n",
    "            if shuffle:\n",
    "                seed = np.random.randint(0,1000)\n",
    "                self._images.shuffle(seed)\n",
    "                self._labels.shuffle(seed)\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size - rest_num_examples\n",
    "            end = self._index_in_epoch\n",
    "            images_new_part = self._images[start:end]\n",
    "            labels_new_part = self._labels[start:end]\n",
    "            \n",
    "            \n",
    "            return np.concatenate((images_rest_part, images_new_part), axis=0),\\\n",
    "                    np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "        else:\n",
    "           \n",
    "            self._index_in_epoch += batch_size\n",
    "            end = self._index_in_epoch\n",
    "            images = self._images[start:end]\n",
    "            labels = self._labels[start:end]\n",
    "            return images,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ClimateImageOrLabel(object):\n",
    "    def __init__(self,filepaths,shape,crop_indices=None, crop_stride=None, variables=[\"TMQ\", \"VBOT\", \"PSL\"],\n",
    "                 time_step_sample_freq=1, time_steps_per_example=1,time_steps_per_file=8):\n",
    "        \n",
    "        assert time_steps_per_example == 1, \"3d not quite supported for labels\"\n",
    "        frame = inspect.currentframe()\n",
    "        # set self.k = v for every k,v pair in __init__ except self of course\n",
    "        self.set_constructor_args(frame)\n",
    "        \n",
    "        self.num_files = len(self.filepaths)\n",
    "        self.examples_per_file = (time_steps_per_file / time_step_sample_freq) / time_steps_per_example\n",
    "        self.total_examples = self.num_files * self.examples_per_file\n",
    "\n",
    "\n",
    "    def set_constructor_args(self,frame):\n",
    "        #set data members for object from constructor args\n",
    "        _, _, _, params = inspect.getargvalues(frame)\n",
    "        del params[\"frame\"]\n",
    "        for k,v in params.iteritems():\n",
    "            setattr(self,k,v)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def shuffle(self, seed):\n",
    "        '''only shufflez files'''\n",
    "        rng = np.random.RandomState(seed)\n",
    "        random.shuffle(self.filepaths, random=rng.uniform)\n",
    "        if self.crop_indices:\n",
    "            rng = np.random.RandomState(seed)\n",
    "            random.shuffle(self.crop_indices, random=rng.uniform)\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    #overloading of bracket operators\n",
    "    def __getitem__(self, slice_):\n",
    "        slices = self.convert_slice_to_file_and_ex_inds(slice_)\n",
    "        if slices is None:\n",
    "            z_shape = tuple([0] + list(self.shape))\n",
    "            return np.zeros(z_shape)\n",
    "        file_slice = slices[\"file_slice\"]\n",
    "        ex_slice = slices[\"ex_slice\"]\n",
    "        filepaths = self.filepaths[file_slice]\n",
    "        if self.crop_indices:\n",
    "            crop_indices = self.crop_indices[file_slice]\n",
    "        else:\n",
    "            crop_indices = None\n",
    "            \n",
    "        tens = self.grab_data_chunk(filepaths, crop_indices)\n",
    "#         lbls = make_multiple_yolo_masks(camfile_paths=filepaths,\n",
    "#                                     labels_csv_file=self.labels_csv_file,\n",
    "#                                     caffe_format=True)\n",
    "        data = tens[ex_slice]\n",
    "#         labels = lbls[ex_slice]\n",
    "        return data\n",
    "    \n",
    "    def convert_slice_to_file_and_ex_inds(self, slice_):\n",
    "        if isinstance(slice_, slice):\n",
    "            start, stop, step = [getattr(slice_,k) for k in [\"start\", \"stop\", \"step\"]]\n",
    "            assert step==1 or step is None, \"step must be 1 or None\"\n",
    "        \n",
    "        elif isinstance(slice_, int):\n",
    "            start, stop = [slice_, slice_ + 1]\n",
    "            \n",
    "        slices =  self.get_file_and_ex_inds(start, stop)\n",
    "        return slices\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    def get_file_and_ex_inds(self, start, stop):\n",
    "        if start == stop:\n",
    "            return None\n",
    "            \n",
    "        #file start stop indices to index filenames\n",
    "        file_start, file_stop = self.get_file_ind(start), self.get_file_ind(stop)\n",
    "        \n",
    "        # get some useful numbers\n",
    "        tot_examples_desired = stop - start \n",
    "        \n",
    "        #relative example indices after examples read in\n",
    "        ex_start = self.get_relative_ex_ind(start)\n",
    "        ex_stop = ex_start + tot_examples_desired\n",
    "\n",
    "        file_slice = slice(file_start,file_stop)\n",
    "        ex_slice = slice(ex_start,ex_stop)\n",
    "        \n",
    "        return {\"file_slice\":file_slice, \"ex_slice\": ex_slice}\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def get_file_ind(self,ex_ind):\n",
    "        return ex_ind / self.examples_per_file\n",
    "\n",
    "    def get_relative_ex_ind(self, ex_ind):\n",
    "        return ex_ind % self.examples_per_file\n",
    "        \n",
    "        \n",
    "        \n",
    "    def grab_data_chunk(self, filepaths, crop_indices=None):\n",
    "        \"\"\"grabs input data (converts filepaths to np tensors)\n",
    "        returns len(filepaths)*4, 16, 768,1152 array\"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "        dsets=[]\n",
    "        for filepath in filepaths:\n",
    "            dataset=nc.Dataset(filepath)\n",
    "            if \"x_coord\" in self.variables:\n",
    "                is_label = True\n",
    "            else:\n",
    "                is_label = False\n",
    "            tensor = convert_nc_data_to_tensor(dataset,\n",
    "                                               self.variables, is_label,\n",
    "                                               self.time_step_sample_freq,\n",
    "                                               self.time_steps_per_example)\n",
    "            xdim = tensor.shape[2]\n",
    "            #hard code crop to 768\n",
    "            tensor = tensor[:,:,:,:xdim]\n",
    "            dsets.append(tensor)\n",
    "        tensor = np.vstack(tuple(dsets))\n",
    "            \n",
    "        \n",
    " \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_datasets(num_examples=-1, typ=\"tr\"):\n",
    "    #Datasets = collections.namedtuple('Datasets', ['tr', 'val', 'test'])#, \"tr_unlabelled\"])\n",
    "    data_list_dir = configs[\"data_list_dir\"]\n",
    "    climate_data = make_dataset(data_list_dir, typ, num_examples)\n",
    "    #tr, val, test = [make_dataset(data_list_dir,type_,num_examples=num_examples) for type_ in ['tr', 'val', 'test']]#, \"tr_unlabelled\"]]\n",
    "    #climate_data = Datasets(tr=tr, val=val, test=test)#, tr_unlabelled=tr_unlabelled)\n",
    "    return climate_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dataset(data_list_dir, type_, num_examples):\n",
    "    \n",
    "    im_files = get_files_from_list(data_list_dir, type_, \"image\")\n",
    "    lbl_files = get_files_from_list(data_list_dir, type_, \"label\")\n",
    "    if num_examples != -1:\n",
    "        num_files = (configs[\"time_step_sample_frequency\"] * num_examples) / configs[\"time_steps_per_file\"]\n",
    "        if num_files <= len(im_files):\n",
    "            im_files = im_files[:num_files]\n",
    "            lbl_files = lbl_files[:num_files]\n",
    "    \n",
    "    #crop_indices = get_files_from_list(data_list_dir, type_, \"crop_indices\")\n",
    "    crop_indices=None\n",
    "    \n",
    "    \n",
    "    #camfiles = get_camfiles(data_dir, configs[type_ + \"_years\"], with_dir=True)\n",
    "    images = ClimateImageOrLabel(filepaths=im_files, shape=(16,768,768),\n",
    "                                 crop_indices=crop_indices, \n",
    "                                 time_step_sample_freq=configs[\"time_step_sample_frequency\"],\n",
    "                                 variables=configs[\"image_variables\"],\n",
    "                                 time_steps_per_example=configs[\"time_steps_per_example\"])\n",
    "    \n",
    "    \n",
    "    labels = ClimateImageOrLabel(filepaths=lbl_files,shape=(6,24,24),\n",
    "                                 crop_indices=crop_indices,\n",
    "                                 variables=configs[\"label_variables\"],\n",
    "                                 time_step_sample_freq=configs[\"time_step_sample_frequency\"],\n",
    "                                 time_steps_per_example=configs[\"time_steps_per_example\"])\n",
    "    \n",
    "    \n",
    "    dataset = DataSet(images,labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_files_from_list(list_dir, type_, images_or_labels_or_crop_indices):\n",
    "    with open(join(list_dir, type_ + \"_\" + images_or_labels_or_crop_indices + \"_files.txt\"), \"r\") as f:\n",
    "        return [line.strip(\"\\n\") for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cl_data = make_datasets(num_tr_examples=22)\n",
    "\n",
    "    im, lbl = cl_data.next_batch(batch_size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
