{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../../notebooks_src/metrics/mAP.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/utils.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/encode.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/make_anchors_orig.ipynb\n",
      "box_encode_decode_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/box_encode_decode_configs.ipynb\n",
      "tensorboard_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/tensorboard_configs.ipynb\n",
      "fit_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/fit_configs.ipynb\n",
      "labels_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/labels_configs.ipynb\n",
      "load_data_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/load_data_configs.ipynb\n",
      "losses_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/losses_configs.ipynb\n",
      "metrics_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/metrics_configs.ipynb\n",
      "models_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/models_configs.ipynb\n",
      "optimizers_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/optimizers_configs.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/get_generator.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/generator/generator.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/util.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/generator/batch_fetcher.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/utils.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/decode.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/ssd.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/tf_extended/math.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/tf_extended/tensors.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/bboxes.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/unpack.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/metrics/utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.append(\"../../\")\n",
    "from notebooks_src.metrics.mAP import calc_batch_metrics, EpochMetrics, calc_ap_one_class\n",
    "from notebooks_src.configs import configs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit(model, generator, val_generator,num_epochs, loss_func, opt):\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        tr_steps_per_epoch= generator.num_ims / generator.batch_size\n",
    "        val_steps_per_epoch = val_generator.num_ims / val_generator.batch_size\n",
    "        \n",
    "        \n",
    "        y_true, y_preds = get_y_true_y_preds_tensors(model, generator.batch_size,generator.data.labels.shape[1:])\n",
    "        \n",
    "        with tf.name_scope(\"loss\"):\n",
    "            loss_tensor = loss_func(y_true, y_preds)\n",
    "            tf.summary.scalar(\"loss\", loss_tensor)\n",
    "        \n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            accuracy_tensor = tf.placeholder(dtype=tf.float32, shape=())\n",
    "            tf.summary.scalar(\"accuracy\", accuracy_tensor)\n",
    "            \n",
    "        sum_accuracy = tf.add(sum_accuracy, accuracy_tensor)\n",
    "        summaries_dir = get_summaries_dir()\n",
    "        train_writer = tf.summary.FileWriter(summaries_dir + '/train',\n",
    "                                      sess.graph)\n",
    "        val_writer = tf.summary.FileWriter(summaries_dir + '/val')\n",
    "        \n",
    "        \n",
    "        \n",
    "        input_ = model.input\n",
    "\n",
    "        train_step = opt.minimize(loss_tensor)\n",
    "        \n",
    "        merged = tf.summary.merge_all()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        tr_global_step_counter = 0\n",
    "        val_global_step_counter = 0\n",
    "        for ep in range(num_epochs):\n",
    "            \n",
    "            tr_mAP, tr_APs = get_epoch_accuracy(generator, model, sess, input_)\n",
    "            val_mAP, val_APs = get_epoch_accuracy(val_generator, model, sess, input_)\n",
    " \n",
    "            for step in range(tr_steps_per_epoch):\n",
    "                im, boxes = generator.next()\n",
    "                _,summary = sess.run([train_step, merged],feed_dict={input_:im, y_true:boxes, accuracy_tensor:tr_mAP})\n",
    "                train_writer.add_summary(summary,tr_global_step_counter)\n",
    "                tr_global_step_counter += 1\n",
    "                \n",
    "            \n",
    "            for step in range(val_steps_per_epoch):\n",
    "                im, boxes = generator.next()\n",
    "                summary, val_loss = sess.run([merged, loss_tensor], feed_dict={input_:im, y_true:boxes, accuracy_tensor:val_mAP})\n",
    "                val_writer.add_summary(summary, val_global_step_counter)\n",
    "                val_global_step_counter += 1\n",
    "  \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_summaries_dir():\n",
    "    if configs[\"exp_name\"] == \"None\":\n",
    "        exp_name = \"_\".join([configs[\"base_model\"], configs[\"detection_model\"]]) + \"_\" + str(int(time.time()))\n",
    "    else:\n",
    "        exp_name = configs[\"exp_name\"]\n",
    "    return join(configs[\"logs_dir\"],exp_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_epoch_accuracy(generator, model, sess,input_):\n",
    "    epm = EpochMetrics()\n",
    "    batch_accuracy_tensors, y_true = get_batch_accuracy_tensors(calc_batch_metrics, model, generator)\n",
    "    steps_per_epoch = generator.num_ims / generator.batch_size\n",
    "    for step in range(steps_per_epoch):\n",
    "        im, boxes = generator.next()\n",
    "        updated_metrics = sess.run(batch_accuracy_tensors, feed_dict={y_true:boxes, input_:im})\n",
    "        epm.update_metrics(*updated_metrics)\n",
    "\n",
    "    final_metrics = epm.get_final_metrics()\n",
    "    aps_voc12, placeholders= calc_ap_one_class()\n",
    "    all_aps12 = {}\n",
    "\n",
    "\n",
    "    for c in final_metrics[0].keys():\n",
    "        placefillers = [d[c] for d in final_metrics]\n",
    "        all_aps12[c] = sess.run(aps_voc12, feed_dict = dict(zip(placeholders, placefillers)) )\n",
    "\n",
    "\n",
    "    mAP = np.mean(all_aps12.values())\n",
    "    return mAP, all_aps12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_true_y_preds_tensors(model, batch_size, label_shape):\n",
    "    output_tensors = model.outputs\n",
    "        \n",
    "    label_batch_shape = tuple([batch_size] + list(label_shape))\n",
    "        \n",
    "        \n",
    "    label_tensor = tf.placeholder(tf.float32,shape=label_batch_shape, name=\"label\")\n",
    "    return label_tensor, output_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_accuracy_tensors(acc_func, model,generator):\n",
    "        batch_size = generator.batch_size\n",
    "        y_true, y_preds = get_y_true_y_preds_tensors(model, batch_size,generator.data.labels.shape[1:])\n",
    "        batch_metrics = calc_batch_metrics(y_true, y_preds)\n",
    "        return batch_metrics, y_true\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
