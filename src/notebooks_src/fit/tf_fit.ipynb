{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../../notebooks_src/metrics/mAP.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/losses/util.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/configs.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/models/configs.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/config_util.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/configs.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/encode.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/make_anchors_orig.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/get_generator.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/generator/generator.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/util.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/generator/batch_fetcher.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/decode.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/metrics/configs.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/ssd.ipynb\n",
      "['', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/home/evan/.local/lib/python2.7/site-packages', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/local/lib/python2.7/dist-packages/IPython/extensions', '/home/evan/.ipython', '../../']\n",
      "importing Jupyter notebook from ../../notebooks_src/tf_extended/math.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/tf_extended/tensors.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/bboxes.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/utils.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/metrics/util.ipynb\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e7efabb247e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnotebooks_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmAP\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalc_batch_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEpochMetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_ap_one_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/evan/hur-detect/src/notebooks_src/fit/nbfinder.pyc\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# run the code in themodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evan/hur-detect/src/notebooks_src/metrics/mAP.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.append(\"../../\")\n",
    "from notebooks_src.metrics.mAP import calc_batch_metrics, EpochMetrics, calc_ap_one_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit(model, generator, val_generator,num_epochs, loss_func, opt):\n",
    "    with tf.Session() as sess:\n",
    "        steps_per_epoch= generator.num_ims / generator.batch_size\n",
    "        val_steps_per_epoch = val_generator.num_ims / val_generator.batch_size\n",
    "        input_ = model.input\n",
    "        loss_tensor, label  = get_loss_tensor(loss_func, model, generator)\n",
    "\n",
    "        train_step = opt.minimize(loss_tensor)\n",
    "        batch_accuracy_tensors, y_true = get_batch_accuracy_tensors(calc_batch_metrics, model, val_generator)\n",
    "        \n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "        for ep in range(num_epochs):\n",
    "            epm = EpochMetrics()\n",
    "            for step in range(steps_per_epoch):\n",
    "                im, boxes = generator.next()\n",
    "                _,cur_loss = sess.run([train_step, loss_tensor],feed_dict={input_:im,label:boxes})\n",
    "                \n",
    "                print \"loss: %8.4f\"% cur_loss\n",
    "            \n",
    "            for step in range(val_steps_per_epoch):\n",
    "                im, boxes = val_generator.next()\n",
    "                updated_metrics = sess.run(batch_accuracy_tensors, feed_dict={y_true:boxes, input_:im})\n",
    "                epm.update_metrics(*updated_metrics)\n",
    "            \n",
    "            final_metrics = epm.get_final_metrics()\n",
    "            aps_voc12, placeholders= calc_ap_one_class()\n",
    "            all_aps12 = {}\n",
    "    \n",
    "        \n",
    "            for c in final_metrics[0].keys():\n",
    "                placefillers = [d[c] for d in final_metrics]\n",
    "                all_aps12[c] = sess.run(aps_voc12, feed_dict = dict(zip(placeholders, placefillers)) )\n",
    "            \n",
    "\n",
    "            print \"AP's\", all_aps12\n",
    "            mAP12 = np.mean(all_aps12.values())\n",
    "            print \"accuracy: \", mAP12\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "#TODO: add streaming mAP calc for train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_true_y_preds_tensors(model, batch_size, label_shape):\n",
    "    output_tensors = model.outputs\n",
    "        \n",
    "    label_batch_shape = tuple([batch_size] + list(label_shape))\n",
    "        \n",
    "        \n",
    "    label_tensor = tf.placeholder(tf.float32,shape=label_batch_shape, name=\"label\")\n",
    "    return label_tensor, output_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss_tensor(loss_func, model, generator):\n",
    "        batch_size = generator.batch_size\n",
    "        \n",
    "        \n",
    "        y_true, y_preds = get_y_true_y_preds_tensors(model, batch_size,generator.data.labels.shape[1:])\n",
    "        loss_tensor = loss_func(y_true, y_preds)\n",
    "\n",
    "        return loss_tensor, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_accuracy_tensors(acc_func, model,generator):\n",
    "        batch_size = generator.batch_size\n",
    "        y_true, y_preds = get_y_true_y_preds_tensors(model, batch_size,generator.data.labels.shape[1:])\n",
    "        batch_metrics = calc_batch_metrics(y_true, y_preds)\n",
    "        return batch_metrics, y_true\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
