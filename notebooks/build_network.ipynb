{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import *\n",
    "from lasagne.objectives import *\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import sys\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import inspect\n",
    "from lasagne.nonlinearities import *\n",
    "from lasagne.objectives import *\n",
    "from helper_fxns import get_detec_loss,get_all_boxes, get_MAP\n",
    "import copy\n",
    "#if __name__ == \"__main__\":\n",
    "    #from data_loader import load_classification_dataset, load_detection_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_hyperparams(frame):\n",
    "    args, _, _, values = inspect.getargvalues(frame)\n",
    "    #return dict(zip(args,values))\n",
    "    #del values['frame']\n",
    "    return values\n",
    "\n",
    "def build_network(kwargs):\n",
    "    \n",
    "    '''Takes a pretrained classification net and adds a few convolutional layers on top of it\n",
    "    and defines a detection loss function'''\n",
    "    '''Args:\n",
    "                      \n",
    "                      num_convpool: number of conv layer-pool layer pairs\n",
    "                      delta: smoothing constant to loss function (ie sqrt(x + delta)) \n",
    "                            -> if x is 0 gradient is undefined\n",
    "                      num_filters\n",
    "                      num_fc_units\n",
    "                      num_extra_conv: conv layers to add on to each conv layer before max pooling\n",
    "                      nonlinearity: which nonlinearity to use throughout\n",
    "                      n_boxes: how many boxes should be predicted at each grid point,\n",
    "                      nclass: how many classes are we predicting,\n",
    "                      grid_size: size of the grid that encodes various \n",
    "                                locations of image (ie in the YOLO paper they use 7x7 grid)\n",
    "                      w_init: weight intitialization\n",
    "                      dropout_p: prob of dropping unit\n",
    "                      coord_penalty : penalty in YOLO loss function for getting coordinates wrong\n",
    "                      nonobj_penalty: penalty in YOLO loss for guessing object when there isn't one\n",
    "                      learning_rate\n",
    "                      weight_decay\n",
    "                      momentum\n",
    "                      load: whether to load weights or not\n",
    "                      load_path: path for loading weights'''\n",
    "\n",
    "    \n",
    "    input_var = T.tensor4('input_var')\n",
    "    target_var = T.tensor4('target_var') #is of shape (grid_size, grid_size,(n_boxes* 5 + nclass)\n",
    "    \n",
    "    print \"Building model and compiling functions...\" \n",
    "    \n",
    "    #make layers\n",
    "    networks = build_layers(input_var,kwargs)\n",
    "    \n",
    "    #load in any pretrained weights\n",
    "    if kwargs['load_path'] != \"None\":\n",
    "        load_weights(kwargs['load_path'], networks['ae'])\n",
    "    \n",
    "    #compile theano functions\n",
    "    fns = make_fns(networks, input_var, target_var, kwargs)\n",
    "     \n",
    "\n",
    "    return fns, networks\n",
    "\n",
    "def build_layers(input_var, nk):\n",
    "    '''nk: network_kwargs'''\n",
    "    '''conv, extra_convs, pool multiple times then fc with dropout, fc with dropout and softmax then reshape'''\n",
    "    \n",
    "    '''total number of conv layers is num_convpool * (1 + num_extra_conv)'''\n",
    "    \n",
    "    filter_dim = nk['filter_dim']\n",
    "    base_num_filters = nk['num_filters']\n",
    "    num_layers = nk['num_layers']\n",
    "    num_filters = base_num_filters\n",
    "    \n",
    "\n",
    "    filters_list = [128, 256, 512, 768, 1024, 1280]\n",
    "    conv = lasagne.layers.InputLayer(shape=nk['input_shape'])\n",
    "    for i in range(num_layers):\n",
    "        if nk[\"batch_norm\"]:\n",
    "            conv = batch_norm(conv)\n",
    "        if nk['num_filters'] == 128:\n",
    "            num_filters = filters_list[i]\n",
    "        else:\n",
    "            num_filters = nk['num_filters']\n",
    "        conv = Conv2DLayer(conv, \n",
    "                              num_filters=num_filters, \n",
    "                              filter_size=nk['filter_dim'], \n",
    "                              pad=nk['filter_dim'] / 2, \n",
    "                              stride=2,\n",
    "                              W=nk['w_init'], \n",
    "                              nonlinearity=nk['nonlinearity'])\n",
    "\n",
    "    encoder = copy.deepcopy(conv)\n",
    "    for layer in get_all_layers(conv)[::-1]:\n",
    "        if nk[\"batch_norm\"]:\n",
    "            conv = batch_norm(conv)\n",
    "        if isinstance(layer, InputLayer):\n",
    "            break\n",
    "        \n",
    "        conv = InverseLayer(conv, layer)\n",
    "    \n",
    "    ae = copy.deepcopy(conv)\n",
    "\n",
    "    \n",
    "    coord_net = Conv2DLayer(batch_norm(encoder), num_filters=5, filter_size=1, W=nk['w_init'], nonlinearity=rectify)\n",
    "    \n",
    "    class_net = Conv2DLayer(batch_norm(encoder), num_filters=nk['num_classes'], filter_size=1,W=nk['w_init'], nonlinearity=sigmoid)\n",
    "\n",
    "    bbox_reg = ConcatLayer([coord_net, class_net])\n",
    "    \n",
    "    return {'yolo': bbox_reg, 'ae':ae, \"encoder\":encoder}#, \"decoder\":decoder_layers}\n",
    "        \n",
    "\n",
    "def load_weights(pickle_file_path, network):\n",
    "    '''grabs weights from an npz file'''\n",
    "    old_params = pickle.load(open(pickle_file_path, 'r'))\n",
    "\n",
    "    return set_all_param_values(network, old_params)\n",
    "    \n",
    "\n",
    "def make_fns(networks,input_var, target_var, kwargs ):\n",
    "    '''Compiles theano train, test, box_fns'''\n",
    "    #deterministic determines whether to use dropout or not in forward pass\n",
    "    #transpose output to match what loss expects\n",
    "    for k,v in networks.iteritems():\n",
    "        kwargs['logger'].info(\"\\n\" + k + \": \\n\")\n",
    "        for lay in get_all_layers(v):\n",
    "            kwargs[\"logger\"].info(str(lay) + \", \" + str(get_output_shape(lay)))\n",
    "    \n",
    "    yolo = networks['yolo']\n",
    "    ae = networks['ae']\n",
    "    yolo_test_prediction = lasagne.layers.get_output(yolo, deterministic=True, inputs=input_var)\n",
    "    yolo_prediction = lasagne.layers.get_output(yolo, deterministic=False,inputs=input_var)\n",
    "    \n",
    "    ae_test_prediction = lasagne.layers.get_output(ae, deterministic=True,inputs=input_var)\n",
    "    ae_prediction = lasagne.layers.get_output(ae, deterministic=False,inputs=input_var)\n",
    "    \n",
    "    def make_loss(yolo_pred, ae_pred):\n",
    "        yolo_loss = make_yolo_loss(yolo_pred)\n",
    "        ae_loss = make_ae_loss(ae_pred)\n",
    "        \n",
    "        #just to make sure we don't compute this if we don't want to\n",
    "        if kwargs['lambda_ae'] == 0:\n",
    "            loss = yolo_loss\n",
    "        else:\n",
    "            loss = yolo_loss + kwargs['lambda_ae'] * ae_loss\n",
    "        return loss, yolo_loss, ae_loss\n",
    "    \n",
    "    def make_yolo_loss(pred):\n",
    "        loss = get_detec_loss(pred, target_var, kwargs)\n",
    "        weightsl2 = lasagne.regularization.regularize_network_params(yolo, lasagne.regularization.l2)\n",
    "        loss += kwargs['weight_decay'] * weightsl2\n",
    "        return loss.mean()\n",
    "    \n",
    "    def make_ae_loss(pred):\n",
    "        loss = squared_error(pred, input_var)\n",
    "        weightsl2 = lasagne.regularization.regularize_network_params(ae, lasagne.regularization.l2)\n",
    "        loss += kwargs['weight_decay'] * weightsl2\n",
    "        return loss.mean()\n",
    "        \n",
    "    def make_train_fn():\n",
    "        '''takes as input the input, target vars and ouputs a loss'''\n",
    "        \n",
    "        loss, yolo_loss, ae_loss =  make_loss(yolo_prediction, ae_prediction)\n",
    "        \n",
    "        #only using params from yolo here -> because decoder has no new params -> tied weights\n",
    "        params = lasagne.layers.get_all_params(yolo, trainable=True)\n",
    "        updates = lasagne.updates.adam(loss, params,learning_rate=kwargs['learning_rate'])\n",
    "#         if kwargs['lambda_ae'] != 0:\n",
    "#             train_fn = theano.function([input_var, target_var], [loss,yolo_loss, ae_loss], updates=updates)\n",
    "        train_fn = theano.function([input_var, target_var], [loss, yolo_loss, ae_loss], updates=updates)\n",
    "        return train_fn\n",
    "        \n",
    "    \n",
    "    def make_test_or_val_fn():\n",
    "        '''takes as input the input, target vars and ouputs a non-dropout loss and an accuracy (intersection over union)'''\n",
    "        test_loss, yolo_loss, ae_loss = make_loss(yolo_test_prediction,ae_test_prediction)\n",
    "        val_fn = theano.function([input_var, target_var], [test_loss,yolo_loss, ae_loss])\n",
    "        return val_fn\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def make_yolo_pred_fn():\n",
    "        '''takes as input the input, target vars and outputs the predicted grid'''\n",
    "        pred_fn = theano.function([input_var], yolo_test_prediction)\n",
    "        return pred_fn\n",
    "    \n",
    "    def make_ae_pred_fn():\n",
    "        pred_fn = theano.function([input_var], ae_test_prediction)\n",
    "        return pred_fn\n",
    "        \n",
    "    def make_box_fn():\n",
    "        pred_fn = make_yolo_pred_fn()\n",
    "        def box_fn(x, y,conf_thresh=kwargs['conf_thresh'], num_classes=kwargs['num_classes']):\n",
    "            y_tensor = y\n",
    "            pred_tensor = pred_fn(x)\n",
    "            pred_boxes, gt_boxes = get_all_boxes(pred_tensor=pred_tensor, \n",
    "                                                 y_tensor=y_tensor, \n",
    "                                                 conf_thresh=conf_thresh, num_classes=num_classes)\n",
    "            return pred_boxes, gt_boxes\n",
    "        return box_fn\n",
    "            \n",
    "    def make_map_fn():\n",
    "        '''takes as input the input, target vars and outputs the predicted and the ground truth boxes)'''\n",
    "        pred_fn = make_yolo_pred_fn()\n",
    "        def MAP_fn(inp, gt, conf_thresh=0.7, iou_thresh=0.5,num_classes=4):\n",
    "            pred = pred_fn(inp)\n",
    "            MAP = get_MAP(pred,gt, conf_thresh,iou_thresh, num_classes)\n",
    "            return MAP\n",
    "    \n",
    "        return MAP_fn\n",
    "    \n",
    "    train_fn = make_train_fn()\n",
    "    test_or_val_fn = make_test_or_val_fn()\n",
    "    MAP_fn = make_map_fn()\n",
    "    yolo_pred_fn = make_yolo_pred_fn()\n",
    "    ae_pred_fn = make_ae_pred_fn()\n",
    "    box_fn = make_box_fn()\n",
    "    \n",
    "    return {\"tr\":train_fn, \"val\":test_or_val_fn, \"MAP\": MAP_fn, \"rec\": ae_pred_fn, \"box\": box_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
