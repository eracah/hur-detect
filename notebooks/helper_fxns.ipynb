{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "# from print_n_plot import plot_ims_with_boxes, add_bbox, plot_im_with_box\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax3D(x):\n",
    "    #X is batch_size x n_classes x X x Y tensor\n",
    "    s = x.shape\n",
    "    #Flip X to be batch_size*x*y, n_classes -> stack all the one-hot encoded vectors\n",
    "    x_t = x.transpose((0,2,3,1)).reshape((s[0]*s[2]*s[3],s[1]))\n",
    "    # take softmax        \n",
    "    x_sm = T.nnet.softmax(x_t)\n",
    "    #reshape back to #X is batch_size x n_classes x X x Y tensor\n",
    "    x_f = x_sm.reshape((s[0],s[2],s[3],s[1])).transpose((0,3,1,2))\n",
    "    return x_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax4D(x):\n",
    "    #X is batch_size x n_classes x time-steps x X x Y tensor\n",
    "    s = x.shape\n",
    "    #Flip X to be batch_size*x*y, n_classes -> stack all the one-hot encoded vectors\n",
    "    x_t = x.transpose((0,2,3,4,1)).reshape((s[0]*s[2]*s[3]*s[4],s[1]))\n",
    "    # take softmax        \n",
    "    x_sm = T.nnet.softmax(x_t)\n",
    "    #reshape back to #X is batch_size x n_classes x X x Y tensor\n",
    "    x_f = x_sm.reshape((s[0],s[2],s[3],s[4],s[1])).transpose((0,4,1,2,3))\n",
    "    return x_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smoothL1(x):\n",
    "    #x is vector of scalars\n",
    "    lto = T.abs_(x)<1\n",
    "    gteo = T.abs_(x)>=1\n",
    "    new_x = T.set_subtensor(x[lto.nonzero()],0.5 * T.square(x[lto.nonzero()]))\n",
    "    new_x = T.set_subtensor(new_x[gteo.nonzero()], T.abs_(new_x[gteo.nonzero()]) - 0.5)\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_MAP(pred_tensor,y_tensor, conf_thresh, iou_thresh, num_classes):\n",
    "    # gets two N x 9 x 12 x 18 tensors?\n",
    "    #return a float, and two lists of N dictionaries\n",
    "    # each dict has num_class keys pointing to a list of some number of box coords\n",
    "    #print pred_tensor.shape, y_tensor.shape\n",
    "    tot_ap = 0\n",
    "    tot_tp = 0\n",
    "    tot_n = 0\n",
    "    tot_ar = 0\n",
    "#     print pred_tensor.shape\n",
    "#     print y_tensor.shape\n",
    "    for i in range(pred_tensor.shape[0]):\n",
    "        \n",
    "        pred_boxes, gt_boxes = get_boxes(pred_tensor[i], y_tensor[i], conf_thresh=conf_thresh, num_classes=num_classes)\n",
    "        ap, tp, n, ar = get_ap(pred_boxes, gt_boxes, thresh=iou_thresh, conf_thresh=conf_thresh, num_classes=num_classes)\n",
    "        tot_ap += ap\n",
    "        tot_tp += tp\n",
    "        tot_n += n\n",
    "        tot_ar += ar\n",
    "    MAP = float(tot_ap) / pred_tensor.shape[0]\n",
    "    mtp = float(tp) / pred_tensor.shape[0]\n",
    "    mn = float(n) / pred_tensor.shape[0]\n",
    "    MAR = float(tot_ar) / pred_tensor.shape[0]\n",
    "    return MAP, mtp, mn, MAR\n",
    "    \n",
    "def get_all_boxes(pred_tensor,y_tensor,num_classes, conf_thresh):\n",
    "    all_gt_boxes = []\n",
    "    all_pred_boxes = []\n",
    "    for i in range(pred_tensor.shape[0]):\n",
    "        pred_boxes, gt_boxes = get_boxes(pred_tensor[i], y_tensor[i], conf_thresh,num_classes)\n",
    "        all_gt_boxes.append(gt_boxes)\n",
    "        all_pred_boxes.append(pred_boxes)\n",
    "    return all_pred_boxes, all_gt_boxes\n",
    "        \n",
    "        \n",
    "def get_boxes(pred_tensor, y_tensor, conf_thresh, num_classes):\n",
    "    ''' pred_tensor is of shape: 5 + num_classes, x_g, y_g \n",
    "        y_tensor is same shape'''\n",
    "    '''returns two dicts of the form\n",
    "         key (class), value: list of boxes with conf for that class'''\n",
    "    pred_boxes = get_boxes_from_tensor(pred_tensor, num_classes=num_classes)\n",
    "    gt_boxes = get_boxes_from_tensor(y_tensor, num_classes=num_classes)\n",
    "    return pred_boxes, gt_boxes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def get_ap(pred_boxes,gt_boxes, num_classes, thresh, conf_thresh):\n",
    "    '''pred boxes and gt_boxes is a dictionary key (class integer): value: list of boxes'''\n",
    "    chosen_boxes = []\n",
    "    wrong_chosen_boxes = []\n",
    "    z = []\n",
    "    \n",
    "# #for each class\n",
    "#     #sort boxes by confidence for given class\n",
    "#     #print pred_boxes[c]\n",
    "\n",
    "#     #print pred_boxes[c]\n",
    "#     #grab boxes for that class\n",
    "#     pc_boxes = pred_boxes[c]\n",
    "    gc_boxes = deepcopy(gt_boxes)\n",
    "    \n",
    "    #for each predicted box (in order from highest conf to lowest)\n",
    "    for pc_box in pred_boxes:\n",
    "        conf = pc_box[4]\n",
    "        #print conf\n",
    "        if conf < conf_thresh:\n",
    "            continue\n",
    "        #get all ious for that box with gt box\n",
    "        ious = np.asarray([iou(pc_box, gc_box) for gc_box in gc_boxes ])\n",
    "        # get all gt boxes that have iou with given box over the threshold\n",
    "        C = [ind for ind, gc_box in enumerate(gc_boxes) if ious[ind] > thresh ]\n",
    "        if len(C) > 0:\n",
    "            # if there are some gt ones that are over the threshold\n",
    "            # grab the highest one in terms of iou\n",
    "            max_ind = np.argmax(ious)\n",
    "\n",
    "            # remove this box from consideration\n",
    "            del gc_boxes[max_ind]\n",
    "            #plop a true positive into the array\n",
    "            z.append(1)\n",
    "            #keep that box around\n",
    "            chosen_boxes.append(pc_box)\n",
    "        else:\n",
    "            z.append(0)\n",
    "            # keep that box around also?\n",
    "            wrong_chosen_boxes.append(pc_box)\n",
    "\n",
    "    n = len(z)\n",
    "    tp = sum(z)\n",
    "\n",
    "    \n",
    "    avg_precision = float(tp) / n if n > 0 else 0.\n",
    "    avg_recall = float(tp) / len(gt_boxes) if len(gt_boxes) > 0 else 0.\n",
    "    return avg_precision, tp , n, avg_recall\n",
    "            \n",
    "        #for pred_clsi_box in pred_clsi_boxes\n",
    "                \n",
    "    \n",
    "\n",
    "def get_boxes_from_tensor(tensor,scale_factor=64., xdim=768, ydim=1152, num_classes=4):\n",
    "    #tensor is numpy tensor\n",
    "    x_g, y_g = tensor.shape[-2], tensor.shape[-1]\n",
    "    boxes = []\n",
    "    \n",
    "    # pull out all box guesses\n",
    "    for i in range(x_g):\n",
    "        for j in range(y_g):\n",
    "            #print tensor.shape\n",
    "            coords = tensor[:5,i,j]\n",
    "            box = convert_coords_to_box(coords,i,j, x_g, y_g, scale_factor)\n",
    "            conf = coords[-1]\n",
    "            cls = np.argmax(tensor[6:,i,j]) # + 1 # cuz classes go from 1 to4\n",
    "            box.append(cls)\n",
    "            if conf > 0.:\n",
    "                boxes.append(box)\n",
    "    \n",
    "    #sort by confidence\n",
    "    boxes.sort(lambda a,b: -1 if a[4] > b[4] else 1)        \n",
    "    return boxes\n",
    "            \n",
    "\n",
    "def convert_coords_to_box(coords, xind, yind, x_g, y_g, scale_factor):\n",
    "    \n",
    "    #print coords\n",
    "    xoff,yoff,w,h, conf = coords\n",
    "    x,y = scale_factor*(xind + xoff), scale_factor *(yind + yoff)\n",
    "\n",
    "    w,h = 2**w * scale_factor, 2**h * scale_factor\n",
    "\n",
    "    return [x,y,w,h,conf]\n",
    "\n",
    "def iou(box1,box2):\n",
    "    #box1 and box2 are numpy arrays\n",
    "    #boxes are expected in x_center, y_center, width, height format\n",
    "    x1,y1,w1,h1 = box1[:4]\n",
    "    x2,y2,w2,h2 = box2[:4]\n",
    "    #print w1,h1\n",
    "    #print w2,h2\n",
    "    xmin1, xmax1, ymin1, ymax1 = max(0, x1 - w1 / 2.), x1 + w1 /2., max(0,y1 - h1 / 2.), y1 + h1 /2.\n",
    "    xmin2, xmax2, ymin2, ymax2 = max(0,x2 - w2 / 2.), x2 + w2 /2,max(0,y2 - h2 / 2), y2 + h2 /2\n",
    "    inters = max(0,(min(xmax1,xmax2) - max(xmin1,xmin2)))   * \\\n",
    "                          max(0,(min(ymax1,ymax2) - max(ymin1,ymin2)) )\n",
    "    def get_area(box_mm):\n",
    "        xmin, xmax, ymin, ymax = box_mm\n",
    "        area = (xmax - xmin) * (ymax - ymin)\n",
    "#         if area == 0.0:\n",
    "#             print \"aaaaaah\", xmin, xmax, ymin, ymax\n",
    "        return area\n",
    "    union = get_area((xmin1, xmax1, ymin1, ymax1)) + get_area((xmin2, xmax2, ymin2, ymax2)) - inters                                                        \n",
    "    \n",
    "    return inters / float(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(nclass=1):\n",
    "    pred_boxes = {cl:box_gen(8).tolist() for cl in range(nclass)}\n",
    "    gt_boxes = pred_boxes\n",
    "    gt_boxes = {cl:box_gen(1).tolist() for cl in range(nclass)}\n",
    "    #return gt_boxes\n",
    "    return calc_tpfp(pred_boxes,gt_boxes, num_classes=nclass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_detec_loss(pred, gt, kwargs):\n",
    "    #TODO add in multiple bbox behavior\n",
    "    #pred is n_ex, [x,y,w,h,c,classes], x, y\n",
    "    #get number of examples and the indices of the tesnor \n",
    "    #to where x,y coirrds height width and confidence go\n",
    "    pred = pred.transpose((0,2,3,1))\n",
    "    gt = gt.transpose((0,2,3,1))\n",
    "    nex = pred.shape[0]\n",
    "    cinds = T.arange(6)\n",
    "    \n",
    "    #x coord indices, y coord indices, width, height, confidence\n",
    "    xs,ys,ws,hs,cs, csn = cinds[0], cinds[1], cinds[2], cinds[3], cinds[4], cinds[5]\n",
    "    \n",
    "    #index for prob vector for all classes\n",
    "    ps = T.arange(6,pred.shape[3])\n",
    "    \n",
    "    #theano will now make elements less than or equal to 0 as zero and others 1 (so output shape is )\n",
    "    obj_inds = gt[:,:, :,cs] > 0.\n",
    "   \n",
    "    #use nonzero in order to get boolean indexing  (eliminate the indices that are zero)\n",
    "    #get specific x,y location of gt objects and the predicted output for that x,y location\n",
    "    tg_obj = gt[obj_inds.nonzero()]\n",
    "    tp_obj = pred[obj_inds.nonzero()]\n",
    "    \n",
    "    #term1\n",
    "    #take the sum of squared difference between predicted and gt for the x and y corrdinate \n",
    "    s_x = smoothL1(tp_obj[:,xs] - tg_obj[:,xs])\n",
    "\n",
    "    s_y = smoothL1(tp_obj[:,ys] - tg_obj[:,ys])\n",
    "\n",
    "    raw_loss1 = T.sum(s_x + s_y)\n",
    "\n",
    "    #multipily by lambda coord (the scaling factor for bbox coords)\n",
    "    sterm1 = kwargs['coord_penalty'] * raw_loss1\n",
    "\n",
    "\n",
    "    #term2\n",
    "\n",
    "    #get sum of squared diff of the of heights and widths b/w pred and gt normalized by squared heights and widths of gt \n",
    "    s_w = smoothL1(tp_obj[:,ws] - tg_obj[:,ws]) #/ T.square(tg_obj[:,ws])\n",
    "    s_h = smoothL1((tp_obj[:,hs] - tg_obj[:,hs])) #/ T.square(tg_obj[:,hs])\n",
    "    raw_loss2 = T.sum(s_w + s_h)\n",
    "\n",
    "    sterm2 = kwargs['size_penalty'] * raw_loss2\n",
    "\n",
    "\n",
    "    #term3\n",
    "    #get sum of squared diff between confidence for places with actual boxes of pred vs. ground truth\n",
    "    s_c  = -T.log(tp_obj[:,cs])\n",
    "    raw_loss3 = T.sum(s_c)\n",
    "    sterm3 = raw_loss3\n",
    "\n",
    "\n",
    "    #term4\n",
    "    #get the real coordinates where there are no objects\n",
    "    no_ind  = gt[:,:,:,cs] <= 0.\n",
    "    tp_no_obj = pred[no_ind.nonzero()]\n",
    "\n",
    "    #get the log likelhood that there isn't a box\n",
    "    s_nc = -T.log(tp_no_obj[:,csn])\n",
    "\n",
    "    raw_loss4 = T.sum(s_nc)\n",
    "\n",
    "    sterm4 = kwargs['nonobj_penalty'] * raw_loss4\n",
    "\n",
    "\n",
    "    #get the cross entropy of these softmax vectors\n",
    "    s_p = T.nnet.categorical_crossentropy(tp_obj[:,ps], tg_obj[:,ps])\n",
    "\n",
    "    raw_loss5 = T.sum(s_p)\n",
    "    sterm5 = raw_loss5\n",
    "\n",
    "    #adds up terms divides by number of examples in the batch\n",
    "    loss = (1. / nex) * (sterm1 + sterm2 + sterm3 + sterm4 + sterm5)\n",
    "    return loss, [sterm1, sterm2, sterm3, sterm4, sterm5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import patches\n",
    "def plot_boxes(pbox_dict=None, gbox_dict=None, nclass=1):\n",
    "    \n",
    "    f,sp = plt.subplots()\n",
    "    sp.imshow((np.zeros((15,15))))\n",
    "    for i in range(nclass):\n",
    "        for box in pbox_dict[i]:\n",
    "            add_bbox(sp, box[:4], color='r')\n",
    "        for box in gbox_dict[i]:\n",
    "            add_bbox(sp, box[:4], color='g')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bbox(subplot, bbox, color):\n",
    "    #box of form center x,y  w,h\n",
    "    x,y,w,h = bbox\n",
    "    subplot.add_patch(patches.Rectangle(\n",
    "    xy=(x - w / 2. , y - h / 2.),\n",
    "    width=w,\n",
    "    height=h, lw=2,\n",
    "    fill=False, color=color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def box_gen(num,xdim=15,ydim=15, maxhw=5):\n",
    "    xs = np.random.randint(0,xdim, size=(num,1))\n",
    "    ys = np.random.randint(0,ydim, size=(num,1))\n",
    "    hws = maxhw*np.ones((num,2))\n",
    "    conf = np.clip(np.random.normal(0.9,0.1,(num,1)),0.,1.)\n",
    "    boxes = np.hstack((xs,ys,hws,conf))\n",
    "    return boxes\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_iou(box1,box2):\n",
    "    #box1 and box2 are tensors\n",
    "    #boxes are expected in x_center, y_center, width, height format\n",
    "    x1,y1,w1,h1 = box1[0], box1[1], box1[2], box1[3]\n",
    "    x2,y2,w2,h2 = box2[0], box2[1], box2[2], box2[3]\n",
    "    xmin1, xmax1, ymin1, ymax1 = T.maximum(0, x1 - w1 / 2.), x1 + w1 /2., T.maximum(0,y1 - h1 / 2.), y1 + h1 /2.\n",
    "    xmin2, xmax2, ymin2, ymax2 = T.maximum(0,x2 - w2 / 2.), x2 + w2 /2,T.maximum(0,y2 - h2 / 2), y2 + h2 /2\n",
    "    inters = T.maximum(0,(T.minimum(xmax1,xmax2) - T.maximum(xmin1,xmin2)))   * \\\n",
    "                          T.maximum(0,(T.minimum(ymax1,ymax2) - T.maximum(ymin1,ymin2)) )\n",
    "    def get_area(box_mm):\n",
    "        xmin, xmax, ymin, ymax = box_mm\n",
    "        return (xmax - xmin) * (ymax - ymin)\n",
    "    union = get_area((xmin1, xmax1, ymin1, ymax1)) + get_area((xmin2, xmax2, ymin2, ymax2)) - inters                                                        \n",
    "    \n",
    "    return inters / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nms(boxes):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_test_data(nclass = 1, grid_y = 6, grid_x = 6, n_bound_box = 1, n_ex = 10,max_objs_per_image = 1 ):\n",
    "    #make test data\n",
    "    xi, yi, wi, hi, Ci,pi = range(5) + [range(5,5 + nclass)]\n",
    "    n_channels = n_bound_box * 5 + nclass\n",
    "    #xi, yi, wi, hi, Ci=[[k + (5*i) for i in range(n_bound_box)] for k in range(5)]\n",
    "\n",
    "    #pi = range(n_channels - nclass, n_channels)\n",
    "\n",
    "\n",
    "\n",
    "    p = np.random.random((n_ex,grid_y,grid_x,n_channels))\n",
    "\n",
    "    g = np.zeros((n_ex,grid_y,grid_x,n_channels))\n",
    "    for ex in g:\n",
    "\n",
    "        n_objs_in_image = 1 #np.random.randint(1,max_objs_per_image,1)[0]\n",
    "        r = np.random.randint(0,grid_y,n_objs_in_image * 2)\n",
    "        for i in range(n_objs_in_image):\n",
    "            coords = np.random.random(4)\n",
    "            c = np.random.randint(0,nclass,1)[0]\n",
    "            ex[r[2*i],r[2*i + 1],pi[c]] = 1.\n",
    "            ex[r[2*i],r[2*i + 1],Ci] = 1.\n",
    "            ex[r[2*i],r[2*i + 1],:Ci] = coords\n",
    "    #         for j in range(n_bound_box):\n",
    "    #             ex[r[2*i],r[2*i + 1],Ci[j]] = 1.\n",
    "    #             ex[r[2*i],r[2*i + 1],(0 if j ==0 else Ci[j-1]+1):Ci[j]] = coords\n",
    "    return g,p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class early_stop(object):\n",
    "    def __init__(self, patience=500):\n",
    "        self.patience = patience   # look as this many epochs regardless\n",
    "        self.patience_increase = 2  # wait this much longer when a new best is\n",
    "                                      # found\n",
    "        self.improvement_threshold = 0.995  # a relative improvement of this much is\n",
    "                                      # considered significant\n",
    "        self.validation_frequency = self.patience // 2\n",
    "                                      # go through this many\n",
    "                                      # minibatche before checking the network\n",
    "                                      # on the validation set; in this case we\n",
    "                                      # check every epoch\n",
    "\n",
    "        self.best_validation_loss = np.inf\n",
    "\n",
    "    def keep_training(self, val_loss, epoch):\n",
    "        print epoch\n",
    "        print val_loss\n",
    "        print self.best_validation_loss\n",
    "        if val_loss < self.best_validation_loss:\n",
    "                #improve patience if loss improvement is good enough\n",
    "                if val_loss < self.best_validation_loss *  \\\n",
    "                   self.improvement_threshold:\n",
    "                    self.patience = max(self.patience, epoch * self.patience_increase)\n",
    "\n",
    "                self.best_validation_loss = val_loss\n",
    "        if self.patience <= epoch:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_hyperparams(dic, path):\n",
    "    new_dic = {k:str(dic[k]) for k in dic.keys()}\n",
    "    with open(path + '/hyperparams.txt', 'w') as f:\n",
    "        for k,v in new_dic.iteritems():\n",
    "            f.write(k + ' : ' + v + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "def setup_logging(save_path):\n",
    "    logger = logging.getLogger('simple_example')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler('%s/training.log'%(save_path))\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    # create console handler with a higher log level\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "    return logger"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
