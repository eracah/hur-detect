{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'racah'\n",
    "import h5py\n",
    "import numpy as np\n",
    "from operator import mul\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "# from print_n_plot import plot_ims_with_boxes\n",
    "%matplotlib inline\n",
    "\n",
    "#1 is hur\n",
    "#0 is nhur\n",
    "\n",
    "#TODO try on 96x96 (use bigger file -> get from cori)\n",
    "def load_hurricane(path,num_ims=-1, detection=False, use_negative=False, seed=7, with_boxes=False):\n",
    "\n",
    "    print 'getting data...'\n",
    "    h5f = h5py.File(path)\n",
    "    if num_ims == -1:\n",
    "        hurs = h5f['hurricanes'][:]\n",
    "        nhurs = h5f['not_hurricanes'][:]\n",
    "        hur_boxes = h5f['hurricane_boxes'][:]\n",
    "    else:\n",
    "        if use_negative:\n",
    "            num_each = num_ims / 2\n",
    "        else:\n",
    "            num_each = num_ims\n",
    "        hurs = h5f['hurricanes'][:num_each]\n",
    "        nhurs = h5f['not_hurricanes'][:num_each]\n",
    "        hur_boxes = h5f['hurricane_boxes'][:num_each]\n",
    "\n",
    "    hurs_bboxes = np.asarray(hur_boxes).reshape(hurs.shape[0],4)\n",
    "    nhurs_bboxes = np.zeros((nhurs.shape[0],4))\n",
    "    \n",
    "    #convert from xmin,ymin,xmax,ymax to x_center, y_center, width, height\n",
    "    hurs_bboxes = convert_bbox_minmax_to_cent_xywh(hurs_bboxes)\n",
    "\n",
    "    if use_negative:\n",
    "        inputs = np.vstack((hurs,nhurs))\n",
    "        bboxes = np.vstack((hurs_bboxes,nhurs_bboxes))\n",
    "    else:\n",
    "        inputs = hurs\n",
    "        bboxes = hurs_bboxes\n",
    "\n",
    "\n",
    "    cl_labels = np.zeros((inputs.shape[0]))\n",
    "    cl_labels[:hurs.shape[0]] = 1\n",
    "    if not num_ims:\n",
    "        num_ims = inputs.shape[0]\n",
    "\n",
    "    print num_ims\n",
    "\n",
    "\n",
    "    tr_i, te_i, val_i = get_train_val_test_ix(num_ims, seed)\n",
    "\n",
    "    return set_up_train_test_val(inputs, bboxes, cl_labels, tr_i, te_i, val_i, detection, with_boxes)\n",
    "\n",
    "\n",
    "def convert_bbox_minmax_to_cent_xywh(bboxes):\n",
    "    #current bbox set up is xmin,ymin,xmax,ymax\n",
    "    xmin, ymin, xmax, ymax = [np.expand_dims(bboxes[:,i], axis=1) for i in range(4)]\n",
    "\n",
    "    w = xmax - xmin\n",
    "    h = ymax - ymin\n",
    "    x_c = xmin + w / 2.\n",
    "    y_c = ymin + h / 2.\n",
    "    new_bboxes = np.hstack((x_c, y_c, w, h))\n",
    "    return new_bboxes\n",
    "    \n",
    "    \n",
    "def get_train_val_test_ix(num_ims,seed):\n",
    "    # tr, te, val is 0.6,0.2,0.2\n",
    "    ix = range(num_ims)\n",
    "\n",
    "    n_te = int(0.2*num_ims)\n",
    "    n_val = int(0.25*(num_ims - n_te))\n",
    "    n_tr =  num_ims - n_te - n_val\n",
    "\n",
    "\n",
    "    #shuffle once deterministically\n",
    "    np.random.RandomState(seed).shuffle(ix)\n",
    "    te_i = ix[:n_te]\n",
    "    rest = ix[n_te:]\n",
    "\n",
    "    np.random.RandomState(seed * 2).shuffle(rest)\n",
    "    val_i = rest[:n_val]\n",
    "    tr_i = rest[n_val:n_val + n_tr]\n",
    "    return tr_i, te_i, val_i\n",
    "\n",
    "\n",
    "def set_up_train_test_val(hurs, boxes, cl_labels, tr_i, te_i, val_i, detection, with_boxes):\n",
    "\n",
    "    #get tr_data\n",
    "    x_tr, bbox_tr, lbl_tr = hurs[tr_i], boxes[tr_i], cl_labels[tr_i]\n",
    "    \n",
    "    #normalize data\n",
    "    x_tr, tr_min, tr_max = normalize(x_tr)\n",
    "    \n",
    "    \n",
    "    # get test and val data and normazlize using statistics from train\n",
    "    x_te,bbox_te, lbl_te = hurs[te_i], boxes[te_i], cl_labels[te_i]\n",
    "    x_te, _ ,_ = normalize(x_te, tr_min, tr_max)\n",
    "    x_val, bbox_val, lbl_val = hurs[val_i], boxes[val_i], cl_labels[val_i]\n",
    "    x_val, _ ,_ = normalize(x_val, tr_min, tr_max)\n",
    "    \n",
    "\n",
    "    x_dims = hurs.shape[1:]\n",
    "    \n",
    "    #get x,y coords of data\n",
    "    x_xy = np.asarray(x_tr.shape[2:])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_tr, y_val, y_te = [y.astype('int32') for y in [lbl_tr, lbl_val, lbl_te]]\n",
    "    if detection:\n",
    "        grid_tr, grid_te, grid_val = create_detection_gr_truth(x_xy, 16, bbox_tr, bbox_te, bbox_val)\n",
    "#         test_grid(grid_tr[5],box_tr[5])\n",
    "        if with_boxes:\n",
    "            return x_tr, grid_tr, bbox_tr, x_te, grid_te, bbox_te, x_val, grid_val, bbox_val\n",
    "        else:\n",
    "            return x_tr, grid_tr, x_te, grid_te, x_val, grid_val\n",
    "    \n",
    "    else:\n",
    "        return x_tr,y_tr, x_te, y_te, x_val,y_val\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# does standardize and normalize for any axis and will return statistics,\n",
    "#so you can fit and run on test and validation (both these features do not come together in sklearn)\n",
    "#otherwise sklearn.preprocessing would be the way to go\n",
    "def standardize(arr,mean=None,std=None, axis=(0,2,3)):\n",
    "    if mean is None or std is None:\n",
    "        mean = arr.mean(axis=axis)\n",
    "        std = arr.std(axis=axis)\n",
    "    arr -= mean\n",
    "    arr /= std\n",
    "    \n",
    "    return arr, mean, std\n",
    "        \n",
    "\n",
    "def normalize(arr,min_=None, max_=None, axis=(0,2,3)):\n",
    "        if min_ is None or max_ is None:\n",
    "            min_ = arr.min(axis=(0,2,3), keepdims=True)\n",
    "\n",
    "            max_ = arr.max(axis=(0,2,3), keepdims=True)\n",
    "\n",
    "        midrange = (max_ + min_) / 2.\n",
    "\n",
    "        range_ = max_ - min_\n",
    "\n",
    "        arr = (arr - midrange) / (range_ /2.)\n",
    "        return arr, min_, max_\n",
    "    \n",
    "\n",
    "    \n",
    "#TODO: load a classification dataset and a localization one   \n",
    "def load_classification_dataset(num_ims=-1, \n",
    "                                path='/global/project/projectdirs/nervana/evan/detection_data/hur_class.h5',\n",
    "                                use_negative=True):\n",
    "    return load_hurricane(path, num_ims=num_ims, detection=False, use_negative=use_negative)\n",
    "\n",
    "\n",
    "def load_detection_dataset(num_ims=-1, \n",
    "                           path='/global/project/projectdirs/nervana/evan/detection_data/hur_detect.h5',\n",
    "                           use_negative=False, with_boxes=False):\n",
    "    return load_hurricane(path, num_ims=num_ims, detection=True, use_negative=use_negative, with_boxes=with_boxes)\n",
    "\n",
    "def create_detection_gr_truth(xy,scale_factor, *bbox_arrays):\n",
    "    #x_xy : 1,2 tuple with x and y sizes for image\n",
    "    #scale_factor: factor to scale xy size by fro gr_truth grid for YOLO\n",
    "    scale_factor = float(scale_factor)\n",
    "\n",
    "    gr_truths = []\n",
    "    #make sure xy coords divide cleanly with scale_factor\n",
    "    assert not np.any(xy % scale_factor), \"scale factor %i must divide the xy (%s) coords cleanly \" %(scale_factor, x_xy)\n",
    "    \n",
    "    \n",
    "    x_len,y_len = xy[0] / scale_factor, xy[1] / scale_factor\n",
    "    last_dim = 6 #x,y,w,h,c plus one binary number for phur or pnot\n",
    "    \n",
    "    for bbox_array in bbox_arrays:\n",
    "        #divide up bbox with has range 0-95 to 0-95/scale_factor (so 6x6 for scale factor of 16)\n",
    "        bb_scaled = bbox_array / scale_factor\n",
    "        \n",
    "        #each coordinate goes at index i,j in the 6x6 array, where i,j are the coordinates of the\n",
    "        #lower left corner of the grid that center of the box (in 6x6 space ) falls on\n",
    "        inds = np.floor(bb_scaled[:,:2]).astype('int')\n",
    "        \n",
    "        #xywh where x and y are offset from lower left corner of grid thay are in [0,1] and w and h\n",
    "        # are what fraction the width and height of bboxes are of the total width and total height of the image\n",
    "        xywh = np.copy(bb_scaled)\n",
    "        \n",
    "        #subtract the floored values to get the offset from the grid cell\n",
    "        xywh[:,:2] -= inds[:,:2].astype('float')\n",
    "        \n",
    "        #divide by scaled width and height to get wdith and height relative to width and height of iage\n",
    "        xywh[:,2] /= x_len\n",
    "        xywh[:,3] /= y_len\n",
    "        \n",
    "        #make gr_truth which is \n",
    "        gr_truth = np.zeros((bbox_array.shape[0],x_len ,y_len, last_dim))\n",
    "        \n",
    "        #sickens me to a do a for loop here, but numpy ain't cooperating\n",
    "        # I tried gr_truth[np.arange(gr_truth.shape[0]),inds[:0], inds[:1]][:,4] = xywh\n",
    "        #but it did not work\n",
    "        \n",
    "        # we assume one box per image here\n",
    "        # for each grid point that is center of image plop in center, and width and height and class\n",
    "        for i in range(gr_truth.shape[0]):\n",
    "            #put coordinates\n",
    "            gr_truth[i,inds[i,0], inds[i,1], :4] = xywh[i]\n",
    "            \n",
    "            #put in confidence\n",
    "            gr_truth[i,inds[i,0], inds[i,1], 4] = 1 if np.sum(xywh[i]) > 0. else 0.\n",
    "            \n",
    "            #put in class label\n",
    "            gr_truth[i,inds[i,0], inds[i,1], 5] = 1 if np.sum(xywh[i]) > 0. else 0.\n",
    "        \n",
    "        \n",
    "        gr_truths.append(gr_truth)\n",
    "    return gr_truths\n",
    "\n",
    "def test_grid(bbox, grid):\n",
    "    x,y = bbox[0] / 16, bbox[1] / 16\n",
    "    xo,yo = (bbox[0] % 16) / 16., (bbox[1] % 16) / 16.\n",
    "    w,h = bbox[2] / 16 /6, bbox[3] / 16/6\n",
    "\n",
    "    print grid[x,y,:6]\n",
    "    print np.array([xo,yo,w,h,1.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#test\n",
    "if __name__ == \"__main__\":\n",
    "    x_tr, y_tr,  bbox_tr,grid_tr,\\\n",
    "    x_te, y_te,bbox_te,grid_te,\\\n",
    "    x_val,y_val, bbox_val, grid_val = load_detection_dataset(num_ims=40)\n",
    "    #plot_ims_with_boxes(X_train[:5,0], box_tr, box_tr, epoch=0,save_plots=False, old=False)\n",
    "#     new_box_tr = convert_bbox_minmax_to_cent_xywh(box_tr)\n",
    "#     plot_ims_with_boxes(X_train[:5,0], new_box_tr, new_box_tr, epoch=0,save_plots=False, old=False)\n",
    "    test_grid(bbox_tr[8],grid_tr[8])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
