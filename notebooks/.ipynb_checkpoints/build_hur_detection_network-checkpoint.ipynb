{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from detec_helper_fxns.ipynb\n",
      "importing Jupyter notebook from data_loader.ipynb\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import sys\n",
    "import numpy as np\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import inspect\n",
    "from detec_helper_fxns import get_best_box, get_detec_loss, get_iou, make_test_data, get_detec_acc, get_final_box\n",
    "if __name__ == \"__main__\":\n",
    "    from data_loader import load_classification_dataset, load_detection_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hyperparams(frame):\n",
    "    args, _, _, values = inspect.getargvalues(frame)\n",
    "    #return dict(zip(args,values))\n",
    "    #del values['frame']\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_det_layers(class_net, layers_to_remove,\n",
    "                                  num_filters,\n",
    "                                  num_fc_units,\n",
    "                                  num_extra_conv, \n",
    "                                  nonlinearity,\n",
    "                                  n_boxes,\n",
    "                                  nclass,\n",
    "                                  grid_size,\n",
    "                                  w_init,\n",
    "                                  dropout_p):\n",
    "    \n",
    "    #define some syntatic sugar\n",
    "    conv = lasagne.layers.Conv2DLayer\n",
    "    fc = lasagne.layers.DenseLayer\n",
    "    conv_kwargs = dict(num_filters=num_filters, filter_size=(3,3), pad=1, nonlinearity=nonlinearity, W=w_init)\n",
    "    \n",
    "    #remove the fc, softmax, avg pooling layers\n",
    "    class_net = strip_off_classif_fc_layers(class_net)\n",
    "\n",
    "        \n",
    "    #num_filters x 96 / (2^num_pool) x 96 / (2^num_pool)\n",
    "    network = conv(class_net, **conv_kwargs)\n",
    "    \n",
    "    \n",
    "    #shape: num_filters x 96 / (2^num_pool) x 96 / (2^num_pool)\n",
    "    for i in range(num_extra_conv):\n",
    "        network = conv(network, **conv_kwargs) \n",
    "        \n",
    "    \n",
    "    network = lasagne.layers.dropout(network, p=dropout_p) #shape: same as above\n",
    "    network = fc(network, num_units=num_fc_units, nonlinearity=nonlinearity)  #shape: num_fc_units\n",
    "    network = lasagne.layers.dropout(network, p=dropout_p) #shape: same as above\n",
    "    network = fc(network, num_units=(grid_size * grid_size) * (n_boxes* 5 + nclass),\n",
    "                                    nonlinearity=lasagne.nonlinearities.rectify)  \n",
    "                                    #shape: (grid_size * grid_size) * (n_boxes* 5 + nclass)     \n",
    "    network = lasagne.layers.ReshapeLayer(network, shape=([0],grid_size, grid_size,(n_boxes* 5 + nclass)))\n",
    "                                    #shape: grid_size, grid_size,(n_boxes* 5 + nclass))\n",
    "    \n",
    "    return network\n",
    "    \n",
    "\n",
    "def strip_off_classif_fc_layers(class_net):\n",
    "    while class_net.name != 'avg_pool_layer':\n",
    "        #keep cutting off layers until you get to the avg pool layer\n",
    "        class_net = class_net.input_layer\n",
    "    #then cut off the avg pool later\n",
    "    class_net = class_net.input_layer\n",
    "    return class_net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_det_network(class_net, input_var,\n",
    "                      layers_to_remove=3,\n",
    "                      num_filters=512,\n",
    "                      num_fc_units=1024,\n",
    "                      num_extra_conv=1, \n",
    "                      nonlinearity=lasagne.nonlinearities.LeakyRectify(0.1),\n",
    "                      n_boxes=1,\n",
    "                      nclass=1,\n",
    "                      grid_size=6,\n",
    "                      w_init=lasagne.init.HeUniform(),\n",
    "                      dropout_p=0.5,\n",
    "                      lc = 5, #penalty for getting coordinates wrong\n",
    "                      ln = 0.5, #penalty for guessing object when there isnt one\n",
    "                      learning_rate = 0.001,\n",
    "                      weight_decay = 0.0005,\n",
    "                      momentum = 0.9,\n",
    "                      load=False,\n",
    "                      load_path=None):\n",
    "    \n",
    "\n",
    "    hyperparams = get_hyperparams(inspect.currentframe())\n",
    "    #define target_var\n",
    "    det_target_var = T.tensor4('det_target_var') #is of shape (grid_size, grid_size,(n_boxes* 5 + nclass)\n",
    "    \n",
    "    print \"Building model and compiling functions...\" \n",
    "    \n",
    "    #make layers\n",
    "    network = build_det_layers(class_net, layers_to_remove,\n",
    "                                  num_filters,\n",
    "                                  num_fc_units,\n",
    "                                  num_extra_conv, \n",
    "                                  nonlinearity,\n",
    "                                  n_boxes,\n",
    "                                  nclass,\n",
    "                                  grid_size,\n",
    "                                  w_init,\n",
    "                                  dropout_p)\n",
    "    \n",
    "    #load in any pretrained weights\n",
    "    if load:\n",
    "        network = load_weights(load_path, network)\n",
    "    \n",
    "    #compile theano functions\n",
    "    train_fn, val_fn, box_fn = make_fns(network,input_var, det_target_var, lc, ln,\n",
    "                                        learning_rate, momentum, weight_decay)\n",
    "    \n",
    "    return train_fn, val_fn, box_fn, network, hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_weights(file_path, network):\n",
    "        with np.load(file_path) as f:\n",
    "            param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "            lasagne.layers.set_all_param_values(network, param_values)\n",
    "        return network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_fns(network,input_var, det_target_var, lc, ln, learning_rate, momentum, weight_decay):\n",
    "    '''Compiles theano train, test, box_fns'''\n",
    "    #deterministic determines whether to use dropout or not in forward pass\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    prediction = lasagne.layers.get_output(network, deterministic=False)\n",
    "    \n",
    "    \n",
    "    def make_loss(pred):\n",
    "        loss = get_detec_loss(pred, det_target_var, lc, ln)\n",
    "        weightsl2 = lasagne.regularization.regularize_network_params(network, lasagne.regularization.l2)\n",
    "        loss += weight_decay * weightsl2\n",
    "        return loss\n",
    "    \n",
    "    def make_train_fn():\n",
    "        '''takes as input the input, target vars and ouputs a loss'''\n",
    "        \n",
    "        loss =  make_loss(prediction)\n",
    "        weightsl2 = lasagne.regularization.regularize_network_params(network, lasagne.regularization.l2)\n",
    "        params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "        updates = lasagne.updates.nesterov_momentum(loss, \n",
    "                                                    params, \n",
    "                                                    learning_rate=learning_rate, \n",
    "                                                    momentum=momentum)\n",
    "        train_fn = theano.function([input_var, det_target_var], loss, updates=updates)\n",
    "        return train_fn\n",
    "        \n",
    "    \n",
    "    def make_test_or_val_fn():\n",
    "        '''takes as input the input, target vars and ouputs a non-dropout loss and an accuracy (intersection over union)'''\n",
    "        test_loss = make_loss(test_prediction)\n",
    "        test_acc = get_detec_acc(test_prediction, det_target_var)\n",
    "        val_fn = theano.function([input_var, det_target_var], [test_loss, test_acc])\n",
    "        return val_fn\n",
    "    \n",
    "    \n",
    "    def make_box_fn():\n",
    "        '''takes as input the input, target vars and outputs the predicted and the ground truth boxes)'''\n",
    "        pred_boxes = get_final_box(test_prediction)\n",
    "        gt_boxes = get_final_box(det_target_var)\n",
    "        box_fn = theano.function([input_var, det_target_var], [pred_boxes, gt_boxes])\n",
    "        return box_fn\n",
    "    \n",
    "    def make_pred_fn():\n",
    "        '''takes as input the input, target vars and outputs the predicted grid'''\n",
    "        pred_fn = theano.function([input_var], test_prediction)\n",
    "        return pred_fn\n",
    "        \n",
    "        \n",
    "    train_fn = make_train_fn()\n",
    "    test_or_val_fn = make_test_or_val_fn()\n",
    "    box_fn = make_box_fn()\n",
    "    pred_fn = make_pred_fn()\n",
    "    return train_fn, test_or_val_fn, box_fn #,pred_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from build_hur_classif_network.ipynb\n",
      "Building model and compiling functions...\n",
      "Building model and compiling functions...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need more than 4 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3a6f5c575d8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_classif_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_fc_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_det_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_fc_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_te\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid_te\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_detection_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_ims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need more than 4 values to unpack"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from build_hur_classif_network import build_classif_network\n",
    "\n",
    "\n",
    "    _,_,inp,cn = build_classif_network(dropout_p=0, input_shape=(None,1,96,96),num_filters=20, num_fc_units=50 )\n",
    "\n",
    "    train_fn, val_fn,pred_fn, box_fn,loss,inp,tv, network = build_det_network(cn, inp, num_filters=20, num_fc_units=50)\n",
    "\n",
    "    x_tr, grid_tr,x_te,grid_te,x_v,grid_v = load_detection_dataset(num_ims=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and compiling functions...\n",
      "Building model and compiling functions...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from build_hur_classif_network import build_classif_network\n",
    "\n",
    "\n",
    "    _,_,inp,cn = build_classif_network(dropout_p=0, input_shape=(None,8,96,96) )\n",
    "\n",
    "    train_fn, val_fn,box_fn,network = build_det_network(cn, inp)\n",
    "\n",
    "   # x_tr, grid_tr,x_te,grid_te,x_v,grid_v = load_detection_dataset(num_ims=20)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
