{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "# from print_n_plot import plot_ims_with_boxes, add_bbox, plot_im_with_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_iou(box1,box2):\n",
    "    #box1 and box2 are tensors\n",
    "    #boxes are expected in x_center, y_center, width, height format\n",
    "    x1,y1,w1,h1 = box1[0], box1[1], box1[2], box1[3]\n",
    "    x2,y2,w2,h2 = box2[0], box2[1], box2[2], box2[3]\n",
    "    xmin1, xmax1, ymin1, ymax1 = T.maximum(0, x1 - w1 / 2.), x1 + w1 /2., T.maximum(0,y1 - h1 / 2.), y1 + h1 /2.\n",
    "    xmin2, xmax2, ymin2, ymax2 = T.maximum(0,x2 - w2 / 2.), x2 + w2 /2,T.maximum(0,y2 - h2 / 2), y2 + h2 /2\n",
    "    inters = T.maximum(0,(T.minimum(xmax1,xmax2) - T.maximum(xmin1,xmin2)))   * \\\n",
    "                          T.maximum(0,(T.minimum(ymax1,ymax2) - T.maximum(ymin1,ymin2)) )\n",
    "    def get_area(box_mm):\n",
    "        xmin, xmax, ymin, ymax = box_mm\n",
    "        return (xmax - xmin) * (ymax - ymin)\n",
    "    union = get_area((xmin1, xmax1, ymin1, ymax1)) + get_area((xmin2, xmax2, ymin2, ymax2)) - inters                                                        \n",
    "    \n",
    "    return inters / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_box(tens):\n",
    "    #assumes there is a box\n",
    "    #TODO: If no box over a certain confidence, then don't output a box\n",
    "    #TODO: Add NMS (non -maximal suppression)\n",
    "    #Links for how do it:\n",
    "        #https://github.com/sunshineatnoon/Darknet.keras/blob/master/RunTinyYOLO.py#L107\n",
    "    #keep it simple right now. just get the best box\n",
    "    \n",
    "    #flatten x,y coords\n",
    "    fl_ten = tens.reshape((tens.shape[0],tens.shape[1] * tens.shape[2], tens.shape[3]))\n",
    "\n",
    "    #filter out boxes less than 0.6?\n",
    "    #fl_ten = fl_tens[:,:,4]\n",
    "    \n",
    "    #get best xy coord for each example\n",
    "    best_ind = T.argmax(fl_ten[:,:,4], axis=1)\n",
    "\n",
    "    #get x,y,w,h,conf from best one xy coord from each exampe\n",
    "    best_xywhc = fl_ten[T.arange(fl_ten.shape[0]),best_ind,:]\n",
    "    \n",
    "    #convert xy coords of where on the grid back to separate x,y\n",
    "    xs = best_ind // tens.shape[1]\n",
    "    ys = best_ind % tens.shape[1]\n",
    "    x = (xs + best_xywhc[:,0])\n",
    "    y = (ys + best_xywhc[:,1])\n",
    "    w = best_xywhc[:,2] * tens.shape[1]\n",
    "    h = best_xywhc[:,3] * tens.shape[2]\n",
    "    coords = T.stack([x,y,w,h],axis=1)\n",
    "    \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_final_box(tens, scale_factor=16):\n",
    "    coords = get_best_box(tens)\n",
    "    return coords * scale_factor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nms(boxes):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_test_data(nclass = 1, grid_y = 6, grid_x = 6, n_bound_box = 1, n_ex = 10,max_objs_per_image = 1 ):\n",
    "    #make test data\n",
    "    xi, yi, wi, hi, Ci,pi = range(5) + [range(5,5 + nclass)]\n",
    "    n_channels = n_bound_box * 5 + nclass\n",
    "    #xi, yi, wi, hi, Ci=[[k + (5*i) for i in range(n_bound_box)] for k in range(5)]\n",
    "\n",
    "    #pi = range(n_channels - nclass, n_channels)\n",
    "\n",
    "\n",
    "\n",
    "    p = np.random.random((n_ex,grid_y,grid_x,n_channels))\n",
    "\n",
    "    g = np.zeros((n_ex,grid_y,grid_x,n_channels))\n",
    "    for ex in g:\n",
    "\n",
    "        n_objs_in_image = 1 #np.random.randint(1,max_objs_per_image,1)[0]\n",
    "        r = np.random.randint(0,grid_y,n_objs_in_image * 2)\n",
    "        for i in range(n_objs_in_image):\n",
    "            coords = np.random.random(4)\n",
    "            c = np.random.randint(0,nclass,1)[0]\n",
    "            ex[r[2*i],r[2*i + 1],pi[c]] = 1.\n",
    "            ex[r[2*i],r[2*i + 1],Ci] = 1.\n",
    "            ex[r[2*i],r[2*i + 1],:Ci] = coords\n",
    "    #         for j in range(n_bound_box):\n",
    "    #             ex[r[2*i],r[2*i + 1],Ci[j]] = 1.\n",
    "    #             ex[r[2*i],r[2*i + 1],(0 if j ==0 else Ci[j-1]+1):Ci[j]] = coords\n",
    "    return g,p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_detec_loss(pred,gt, lc,ln, delta=0.00001):\n",
    "    #TODO add in multiple bbox behavior\n",
    "    \n",
    "    #get number of examples and the indices of the tesnor \n",
    "    #to where x,y coirrds height width and confidence go\n",
    "    #print pred.shape.eval()\n",
    "    #print gt.shape.eval()\n",
    "    nex = pred.shape[0]\n",
    "    cinds = T.arange(5)\n",
    "    \n",
    "    #x coord indices, y coord indices, width, height, confidence\n",
    "    xs,ys,ws,hs,cs = cinds[0], cinds[1], cinds[2], cinds[3], cinds[4]\n",
    "    \n",
    "    #index for prob vector for all classes\n",
    "    ps = T.arange(5,pred.shape[3])\n",
    "    \n",
    "    #theano will now make elements less than or equal to 0 as zero and others 1 (so output shape is )\n",
    "    obj_inds = gt[:,:, :,cs] > 0.\n",
    "   \n",
    "    #use nonzero in order to get boolean indexing  (eliminate the indices that are zero)\n",
    "    #get specific x,y location of gt objects and the predicted output for that x,y location\n",
    "    tg_obj = gt[obj_inds.nonzero()]\n",
    "    tp_obj = pred[obj_inds.nonzero()]\n",
    "    \n",
    "    #term1\n",
    "    #take the sum of squared difference between predicted and gt for the x and y corrdinate \n",
    "    s_x = T.square(tp_obj[:,xs] - tg_obj[:,xs])\n",
    "\n",
    "    s_y = T.square(tp_obj[:,ys] - tg_obj[:,ys])\n",
    "\n",
    "    raw_loss1 = T.sum(s_x + s_y)\n",
    "\n",
    "    #multipily by lambda coord (the scaling factor for bbox coords)\n",
    "    sterm1 = lc * raw_loss1\n",
    "\n",
    "\n",
    "    #term2\n",
    "\n",
    "    #get sum of squared diff of the sqrt of heights and widths b/w pred and gt\n",
    "    s_w = T.square(T.sqrt(tp_obj[:,ws] + delta) - T.sqrt(tg_obj[:,ws] + delta))\n",
    "    s_h = T.square(T.sqrt(tp_obj[:,hs] + delta) - T.sqrt(tg_obj[:,hs] + delta))\n",
    "    raw_loss2 = T.sum(s_w + s_h)\n",
    "\n",
    "    sterm2 = lc * raw_loss2\n",
    "\n",
    "\n",
    "    #term3\n",
    "    #get sum of squared diff between confidence for places with actual boxes of pred vs. ground truth\n",
    "    s_c  = T.square(tp_obj[:,cs] - tg_obj[:,cs])\n",
    "    raw_loss3 = T.sum(s_c)\n",
    "    sterm3 = raw_loss3\n",
    "\n",
    "\n",
    "    #term4\n",
    "    #get the real coordinates where there are no objects\n",
    "    no_ind  = gt[:,:,:,cs] <= 0.\n",
    "    tg_no_obj = gt[no_ind.nonzero()]\n",
    "    tp_no_obj = pred[no_ind.nonzero()]\n",
    "\n",
    "    #get the sum of squared diff of the confidences for the places with no real boxes of  predicted vs. gr_truth\n",
    "    s_nc = T.square(tp_no_obj[:,cs] - tg_no_obj[:,cs])\n",
    "\n",
    "    raw_loss4 = T.sum(s_nc)\n",
    "\n",
    "    sterm4 = ln * raw_loss4\n",
    "\n",
    "    #get the sum of squared diffs for prob vectors for the classes where there is an object in gt vs. pred\n",
    "    s_p = T.square(tp_obj[:,ps] - tg_obj[:,ps])\n",
    "\n",
    "    raw_loss5 = T.sum(s_p)\n",
    "    sterm5 = raw_loss5\n",
    "\n",
    "    #adds up terms divides by number of examples in the batch\n",
    "    terms = (1. / nex) * (sterm1 + sterm2 + sterm3 + sterm4 + sterm5)\n",
    "    return terms\n",
    "\n",
    "#     fterms = theano.function([pred, gt], terms)\n",
    "#     return fterms\n",
    "\n",
    "# fterms = get_detec_train_loss( pred,gt, lam_coord, lam_noobj)\n",
    "# print fterms(p,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_detec_acc(pred,gt):\n",
    "    pbox = get_best_box(pred)\n",
    "    gbox = get_best_box(gt)\n",
    "    #TODO make this elementwise\n",
    "    results, updates = theano.scan(fn=lambda b1,b2: get_iou(b1,b2), sequences=[pbox,gbox])\n",
    "    mean_iou = T.mean(results)\n",
    "    return mean_iou\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class early_stop(object):\n",
    "    def __init__(self, patience=500):\n",
    "        self.patience = patience   # look as this many epochs regardless\n",
    "        self.patience_increase = 2  # wait this much longer when a new best is\n",
    "                                      # found\n",
    "        self.improvement_threshold = 0.995  # a relative improvement of this much is\n",
    "                                      # considered significant\n",
    "        self.validation_frequency = self.patience // 2\n",
    "                                      # go through this many\n",
    "                                      # minibatche before checking the network\n",
    "                                      # on the validation set; in this case we\n",
    "                                      # check every epoch\n",
    "\n",
    "        self.best_validation_loss = np.inf\n",
    "\n",
    "    def keep_training(self, val_loss, epoch):\n",
    "        print epoch\n",
    "        print val_loss\n",
    "        print self.best_validation_loss\n",
    "        if val_loss < self.best_validation_loss:\n",
    "                #improve patience if loss improvement is good enough\n",
    "                if val_loss < self.best_validation_loss *  \\\n",
    "                   self.improvement_threshold:\n",
    "                    self.patience = max(self.patience, epoch * self.patience_increase)\n",
    "\n",
    "                self.best_validation_loss = val_loss\n",
    "        if self.patience <= epoch:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def create_run_dir():\n",
    "    results_dir = './results'\n",
    "    run_num_file = os.path.join(results_dir, \"run_num.txt\")\n",
    "    if not os.path.exists(results_dir):\n",
    "        print \"making results dir\"\n",
    "        os.mkdir(results_dir)\n",
    "\n",
    "    if not os.path.exists(run_num_file):\n",
    "        print \"making run num file....\"\n",
    "        f = open(run_num_file,'w')\n",
    "        f.write('0')\n",
    "        f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    f = open(run_num_file,'r+')\n",
    "\n",
    "    run_num = int(f.readline()) + 1\n",
    "\n",
    "    f.seek(0)\n",
    "\n",
    "    f.write(str(run_num))\n",
    "\n",
    "\n",
    "    run_dir = os.path.join(results_dir,'run%i'%(run_num))\n",
    "    os.mkdir(run_dir)\n",
    "    return run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_hyperparams(dic, path):\n",
    "    new_dic = {k:str(dic[k]) for k in dic.keys()}\n",
    "    with open(path + '/hyperparams.json', 'w') as f:\n",
    "        json.dump(new_dic, f)\n",
    "#     with open(path + '/hyperparams.pkl','w') as g:\n",
    "#         pickle.dump(dic, g)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
